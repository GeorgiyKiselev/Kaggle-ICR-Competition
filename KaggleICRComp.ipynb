{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n",
    "!mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "!cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost\n",
    "import inspect\n",
    "from collections import defaultdict\n",
    "from tabpfn import TabPFNClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "\n",
    "greeks = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_category = train.EJ.unique()[0]\n",
    "train.EJ = train.EJ.eq(first_category).astype('int')\n",
    "test.EJ = test.EJ.eq(first_category).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_for_sub=test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= train.drop(['Id','Class'],axis=1)\n",
    "y = train['Class']\n",
    "\n",
    "test=test.drop(['Id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "\n",
    "    return balanced_log_loss/(N_0+N_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self):\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "        self.classifiers =[xgboost.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n",
    "                           xgboost.XGBClassifier(),\n",
    "                           TabPFNClassifier(N_ensemble_configurations=24),\n",
    "                          TabPFNClassifier(N_ensemble_configurations=64)]\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        X = self.imputer.fit_transform(X)\n",
    "\n",
    "        for classifier in self.classifiers:\n",
    "            if classifier==self.classifiers[2] or classifier==self.classifiers[3]:\n",
    "                classifier.fit(X,y,overwrite_warning =True)\n",
    "            else :\n",
    "                classifier.fit(X, y)\n",
    "     \n",
    "    def predict_proba(self, x):\n",
    "        x = self.imputer.transform(x)\n",
    "        \n",
    "        probabilities = np.stack([classifier.predict_proba(x) for classifier in self.classifiers])\n",
    "        averaged_probabilities = np.mean(probabilities, axis=0)\n",
    "        \n",
    "        class_0_est_instances = averaged_probabilities[:, 0].sum()\n",
    "        others_est_instances = len(averaged_probabilities)-class_0_est_instances\n",
    "\n",
    "        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n",
    "        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold as KF, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, x,y,y_meta):\n",
    "    \n",
    "    outer_results = list()\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    \n",
    "    split = 0\n",
    "    splits = 5\n",
    "    \n",
    "    cv_inner = KF(n_splits = splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx,val_idx in tqdm(cv_inner.split(x), total = splits):\n",
    "        \n",
    "        split+=1\n",
    "        \n",
    "        x_train, x_val = x.iloc[train_idx],x.iloc[val_idx]\n",
    "        y_train, y_val = y_meta[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict_proba(x_val)\n",
    "        \n",
    "        p0=y_pred[:,0]\n",
    "        \n",
    "        p0=np.where(p0>=0.5,0,1)\n",
    "        \n",
    "        p0=p0.reshape(len(p0))\n",
    "        \n",
    "        loss = balanced_log_loss(y_val,p0)\n",
    "\n",
    "        if loss<best_loss:\n",
    "            best_model = model\n",
    "            best_loss = loss\n",
    "            print('best_model_saved')\n",
    "        outer_results.append(loss)\n",
    "        print('>val_loss=%.5f, split = %.1f' % (loss,split))\n",
    "    print('LOSS: %.5f' % (np.mean(outer_results)))\n",
    "    return best_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "times = greeks.Epsilon.copy()\n",
    "times[greeks.Epsilon != 'Unknown'] = greeks.Epsilon[greeks.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\n",
    "times[greeks.Epsilon == 'Unknown'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Epsilon']=times\n",
    "test['Epsilon']=max(times)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "train_ros, y_ros = ros.fit_resample(train, greeks.Alpha)\n",
    "\n",
    "_, y_ros = np.unique(y_ros, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ros = train_ros.drop(['Class', 'Id'],axis=1)\n",
    "y_ = train_ros.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = Ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = training(yt,x_ros,y_,y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict_proba(test)\n",
    "\n",
    "p0 = y_pred[:,0]\n",
    "\n",
    "p0[p0 > 0.62] = 1\n",
    "p0[p0 < 0.26] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(ID_for_sub, columns=[\"Id\"])\n",
    "\n",
    "submission[\"class_0\"] = p0\n",
    "submission[\"class_1\"] = 1 - p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('submission.csv')\n",
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
